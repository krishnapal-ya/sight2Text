{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to the location in drive\n",
    "%cd /content/drive/MyDrive/sight2Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be76164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the requirements\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hugging face login in terminal\n",
    "# huggingface-cli login\n",
    "# then paste the hf token\n",
    "# select n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model from hf and keep it in cache\n",
    "# in model path paste the cached location\n",
    "from huggingface_hub import snapshot_download\n",
    "p = snapshot_download(\"google/paligemma-3b-pt-224\")\n",
    "print(\"Model cached at:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run the inference file\n",
    "!bash launch_inference.sh"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
